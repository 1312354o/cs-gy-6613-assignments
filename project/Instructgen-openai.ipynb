{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Generate Instruction for fine-tuning using gpt4o from openai API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import concurrent.futures\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import List, Tuple\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import Dataset\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructionAnswerSet:\n",
    "    def __init__(self, pairs: List[Tuple[str, str]]):\n",
    "        self.pairs = pairs\n",
    "    @classmethod\n",
    "    def from_json(cls, json_str: str) -> 'InstructionAnswerSet':\n",
    "        data = json.loads(json_str)\n",
    "        pairs = [(pair['instruction'], pair['answer'])\n",
    "                 for pair in data['instruction_answer_pairs']]\n",
    "        return cls(pairs)\n",
    "    def __iter__(self):\n",
    "        return iter(self.pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instruction_answer_pairs(extract):\n",
    "    prompt = f\"\"\"Based on the following extract, generate two instruction-answer pairs. Each instruction \\\n",
    "must ask to write about a specific topic contained in the context. each answer \\\n",
    "must provide a relevant paragraph based on the information found in the \\\n",
    "context. Only use concepts from the context to generate the instructions. \\\n",
    "Instructions must never explicitly mention a context, a system, a course, or an extract. \\\n",
    "Instructions must be self-contained and general. \\\n",
    "Answers must imitate the writing style of the context. \\\n",
    "Example instruction: Introduce ROS2 library. \\\n",
    "Example answer:The Robot Operating System (ROS) is a set of software libraries and tools for building robot applications. \\\n",
    "From drivers and state-of-the-art algorithms to powerful developer tools, ROS has the open source tools you need for your next robotics project \\\n",
    "Since ROS was started in 2007, a lot has changed in the robotics and ROS community.  \\\n",
    "The goal of the ROS 2 project is to adapt to these changes, leveraging what is great about ROS 1 and improving what isn’t. \\\n",
    "Provide your response in JSON format with the following structure:\n",
    "{{\n",
    "    \"instruction_answer_pairs\": [\n",
    "        {{\"instruction\": \"...\", \"answer\": \"...\"}},\n",
    "        ...\n",
    "    ]\n",
    "}}\n",
    "Extract:\n",
    "{extract}\n",
    "\"\"\"\n",
    "    client = OpenAI()\n",
    "    # 使用 OpenAI API 请求生成回答\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \"content\": \"You are a helpful assistant who \\\n",
    "            generates instruction-answer pairs based on the given context. \\\n",
    "            Provide your response in JSON format.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        max_tokens=1200,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generate_instruction_answer_pairs(\"The Robot Operating System (ROS) is a set of software libraries and tools for building robot applications. From drivers and state-of-the-art algorithms to powerful developer tools, ROS has the open source tools you need for your next robotics project.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = InstructionAnswerSet.from_json(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Explain the purpose of ROS.',\n",
       "  'The Robot Operating System (ROS) serves as a comprehensive framework designed to facilitate the development of robot applications. It provides a robust collection of software libraries and tools that enable developers to integrate various functionalities, from hardware drivers to advanced algorithms. With its open-source nature, ROS empowers the robotics community by offering resources that can be utilized for a wide array of projects, ensuring that developers have access to the essential tools needed to bring their robotic innovations to life.'),\n",
       " ('Discuss the evolution of ROS.',\n",
       "  'Since its inception in 2007, the Robot Operating System has undergone significant evolution, adapting to the rapid advancements in robotics technology and the growing demands of the community. The transition to ROS 2 marks a pivotal moment in this evolution, as it aims to build upon the strengths of ROS 1 while addressing its limitations. This ongoing development reflects a commitment to enhancing capabilities, improving interoperability, and ensuring that ROS remains a leading choice for robotics developers looking to leverage the latest innovations in the field.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from datasets import Dataset\n",
    "import json\n",
    "\n",
    "# MongoDB\n",
    "mongo_client = MongoClient(\"mongodb://localhost:27018/\")\n",
    "mongo_db = mongo_client[\"ros2_database\"]\n",
    "mongo_collection = mongo_db[\"ros2_documents\"]\n",
    "\n",
    "\n",
    "\n",
    "def get_extract_from_mongodb(query,collection):\n",
    "    return collection.find(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1985"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = list(mongo_collection.find())\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_answer_pairs=[]\n",
    "i = 0\n",
    "for document in documents:\n",
    "    try:\n",
    "        temp = generate_instruction_answer_pairs(document['content'])\n",
    "        instruction_answer_pairs.extend(InstructionAnswerSet.from_json(temp.content).pairs)\n",
    "    except Exception:\n",
    "        continue ## sometimes gpt4 went up with ill-formed answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions, answers = zip(*instruction_answer_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset= Dataset.from_dict(\n",
    "        {\"instruction\": list(instructions), \"output\": list(answers)}\n",
    "    )\n",
    "filtered_dataset = filtered_dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "#hugging face login\n",
    "login(token=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a309c0a8ee453e87ce413bdeb08b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10da7bb76a204f88baaf5195a655e3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b761579c004b20af2444742624c95e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b581fd88e1bf400fb8aaa622ac18078b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7db74010eca4757b6d36f14d394ac24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/407 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/1312354o/llama-ros2/commit/7c22e6a35481c01f5debaca7bf3ae0c387968f1f', commit_message='Upload dataset', commit_description='', oid='7c22e6a35481c01f5debaca7bf3ae0c387968f1f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/1312354o/llama-ros2', endpoint='https://huggingface.co', repo_type='dataset', repo_id='1312354o/llama-ros2'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dataset.push_to_hub(\"1312354o/llama-ros2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
